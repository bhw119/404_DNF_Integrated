from flask import Flask, request, jsonify
from pymongo import MongoClient
from dotenv import load_dotenv
import os
import re
import sys
import threading
import time
import socket
import uuid
from datetime import datetime
from typing import Any, Dict, List, Optional
from model.predictor import process_image_and_predict, process_text_and_predict, parse_text_blocks

# stdout ë²„í¼ë§ ë¹„í™œì„±í™” (ë¡œê·¸ ì¦‰ì‹œ ì¶œë ¥)
sys.stdout.reconfigure(line_buffering=True)

# í˜„ì¬ ë””ë ‰í† ë¦¬ì™€ ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ .env íŒŒì¼ ë¡œë“œ
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
load_dotenv(os.path.join(BASE_DIR, '.env'))  # model_server/.env
load_dotenv(os.path.join(BASE_DIR, '..', '.env'))  # ìƒìœ„ ë””ë ‰í† ë¦¬ .env
load_dotenv(os.path.join(BASE_DIR, '..', 'server', '.env'))  # server/.env

app = Flask(__name__)

# ë™ì‹œ ì‹¤í–‰ ì‹œ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•œ ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ì‹ë³„ì
SERVER_INSTANCE_ID = os.getenv("MODEL_SERVER_INSTANCE_ID")
if not SERVER_INSTANCE_ID:
    hostname = socket.gethostname()
    pid = os.getpid()
    SERVER_INSTANCE_ID = f"{hostname}-{pid}-{uuid.uuid4().hex[:6]}"
print(f"ğŸ†” [Model Server Instance] {SERVER_INSTANCE_ID}")

# MongoDB ì—°ê²°
MONGODB_URL = os.getenv("MONGODB_URL") or os.getenv("MONGODB_URI")
if not MONGODB_URL:
    print("\n" + "=" * 80)
    print("âŒ [MongoDB ì—°ê²° ì˜¤ë¥˜] MONGODB_URL ë˜ëŠ” MONGODB_URI í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("=" * 80)
    print(".env íŒŒì¼ì— ë‹¤ìŒì„ ì¶”ê°€í•˜ì„¸ìš”:")
    print("MONGODB_URL=mongodb+srv://user:password@cluster.mongodb.net/web?retryWrites=true&w=majority")
    print("=" * 80 + "\n")
    import sys
    sys.exit(1)

# MongoDB URLì—ì„œ ìê²©ì¦ëª… ìˆ¨ê¸°ê¸°
masked_url = re.sub(r'://.*@', '://***:***@', MONGODB_URL) if MONGODB_URL else 'localhost:27017'
print(f"\nğŸ”— [MongoDB ì—°ê²° ì‹œë„] {masked_url}")

try:
    client = MongoClient(MONGODB_URL)
    # ì—°ê²° í…ŒìŠ¤íŠ¸
    client.admin.command('ping')
    db = client["web"]
    predicate_col = db["predicate"]
    extension_col = db["extension"]
    model_col = db["model"]
    print(f"âœ… [MongoDB ì—°ê²° ì„±ê³µ] Database: {db.name}")
    print(f"   - Collections: predicate, extension, model")
    print("=" * 80 + "\n")
except Exception as e:
    print(f"\nâŒ [MongoDB ì—°ê²° ì‹¤íŒ¨] {str(e)}")
    print("=" * 80)
    print("MongoDB ì—°ê²°ì„ í™•ì¸í•˜ì„¸ìš”:")
    print("1. .env íŒŒì¼ì— MONGODB_URLì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸")
    print("2. MongoDB Atlasì˜ ë„¤íŠ¸ì›Œí¬ ì ‘ê·¼ ì„¤ì • í™•ì¸")
    print("3. ì¸í„°ë„· ì—°ê²° í™•ì¸")
    print("=" * 80 + "\n")
    import sys
    sys.exit(1)

# input_imageëŠ” server ë””ë ‰í† ë¦¬ì— ìˆìŒ
INPUT_IMAGE_DIR = os.path.abspath(os.path.join(BASE_DIR, "..", "server", "input_image"))

@app.route("/health", methods=["GET"])
def health():
    """ì„œë²„ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        # MongoDB ì—°ê²° í™•ì¸
        client.admin.command('ping')
        return jsonify({
            "status": "healthy",
            "mongodb": "connected",
            "timestamp": datetime.now().isoformat()
        }), 200
    except Exception as e:
        return jsonify({
            "status": "unhealthy",
            "mongodb": "disconnected",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }), 503

@app.route("/predict", methods=["POST"])
def predict():
    data = request.get_json()
    filename = data.get("filename")

    if not filename:
        return jsonify({"error": "filename ëˆ„ë½ë¨"}), 400

    img_path = os.path.join(INPUT_IMAGE_DIR, filename)
    if not os.path.exists(img_path):
        return jsonify({"error": f"{img_path} ê²½ë¡œì— ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."}), 404

    try:
        prediction_results = process_image_and_predict(img_path)

        # âœ… ì˜ˆì¸¡ ê²°ê³¼ì— filename ì¶”ê°€
        for result in prediction_results:
            result["filename"] = filename

        # âœ… ë‹¤í¬íŒ¨í„´ì¸ ê²½ìš°ë§Œ í•„í„°ë§í•´ì„œ ì €ì¥
        dark_patterns_only = [r for r in prediction_results if r.get("is_darkpattern") == 1]

        if dark_patterns_only:
            predicate_col.insert_many(dark_patterns_only)

        return jsonify({
            "message": "âœ… ì˜ˆì¸¡ ì™„ë£Œ",
            "total": len(prediction_results),
            "saved": len(dark_patterns_only)
        })
    except Exception as e:
        return jsonify({"error": str(e)}), 500

def watch_extension_collection():
    """
    MongoDB extension ì»¬ë ‰ì…˜ì˜ ë³€ê²½ ì‚¬í•­ì„ ê°ì§€í•˜ê³  
    ìƒˆë¡œìš´ ë¬¸ì„œê°€ ì¶”ê°€ë˜ë©´ fullTextë¥¼ * ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ëª¨ë¸ë§í•˜ê³  ê²°ê³¼ë¥¼ model ì»¬ë ‰ì…˜ì— ì €ì¥
    """
    print("\n" + "=" * 80)
    print("ğŸ” [MongoDB ê°ì‹œ ì‹œì‘] Extension ì»¬ë ‰ì…˜ ê°ì‹œ ì¤‘")
    print("=" * 80 + "\n")
    
    # ì²˜ë¦¬ëœ ë¬¸ì„œ IDë¥¼ ì¶”ì  (ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€)
    processed_ids = set()
    retry_count = 0
    max_retries = 3
    
    while retry_count < max_retries:
        try:
            # MongoDB ì—°ê²° í™•ì¸
            try:
                client.admin.command('ping')
            except Exception as conn_err:
                print(f"\nâŒ [MongoDB ì—°ê²° í™•ì¸ ì‹¤íŒ¨] {str(conn_err)}")
                print("MongoDB ì—°ê²°ì„ í™•ì¸í•˜ê³  ì¬ì‹œë„í•©ë‹ˆë‹¤")
                retry_count += 1
                if retry_count < max_retries:
                    time.sleep(5)
                    continue
                else:
                    print("\nâŒ [ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼] MongoDB ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    print("ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ê±°ë‚˜ MongoDB ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
                    return
            
            # Change Streamìœ¼ë¡œ ì‹¤ì‹œê°„ ë³€ê²½ ê°ì§€
            print("âœ… [Change Stream ì—°ê²° ì„±ê³µ] ìƒˆ ë¬¸ì„œ ê°ì§€ ëŒ€ê¸° ì¤‘")
            print("=" * 80 + "\n")
            sys.stdout.flush()
            
            with extension_col.watch([{"$match": {"operationType": "insert"}}]) as stream:
                retry_count = 0  # ì„±ê³µì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¼ì´ ì‹œì‘ë˜ë©´ ì¬ì‹œë„ ì¹´ìš´íŠ¸ ë¦¬ì…‹
                print("ğŸ‘€ [Change Stream í™œì„±í™”] MongoDB extension ì»¬ë ‰ì…˜ ê°ì‹œ ì¤‘\n")
                sys.stdout.flush()
                
                for change in stream:
                    if change["operationType"] == "insert":
                        doc = change["fullDocument"]
                        doc_id = doc.get("_id")
                        
                        # ì´ë¯¸ ì²˜ë¦¬ëœ ë¬¸ì„œëŠ” ìŠ¤í‚µ
                        if doc_id in processed_ids:
                            continue

                    # ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ê°€ ì²˜ë¦¬ ì¤‘ì¸ì§€ í™•ì¸
                    existing_processor = doc.get("processingServerId")
                    if existing_processor and existing_processor != SERVER_INSTANCE_ID:
                        print(f"âš ï¸ [ì„ ì ë¨] ë¬¸ì„œ {doc_id}ëŠ” ë‹¤ë¥¸ ì„œë²„({existing_processor})ê°€ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                        processed_ids.add(doc_id)
                        continue

                    # ì²˜ë¦¬ê¶Œ ì„ ì  (ì›ìì  ì—…ë°ì´íŠ¸)
                    if not existing_processor:
                        claim_result = extension_col.update_one(
                            {"_id": doc_id, "processingServerId": {"$exists": False}},
                            {"$set": {"processingServerId": SERVER_INSTANCE_ID}}
                        )
                        if claim_result.modified_count == 0:
                            claimed_doc = extension_col.find_one({"_id": doc_id}, {"processingServerId": 1})
                            claimed_by = claimed_doc.get("processingServerId") if claimed_doc else None
                            if claimed_by and claimed_by != SERVER_INSTANCE_ID:
                                print(f"âš ï¸ [ê²½ìŸ ê°ì§€] ë¬¸ì„œ {doc_id}ëŠ” ë‹¤ë¥¸ ì„œë²„({claimed_by})ê°€ ì„ ì í–ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                                processed_ids.add(doc_id)
                                continue
                        doc["processingServerId"] = SERVER_INSTANCE_ID
                        
                        # fullText(ë²ˆì—­ëœ í…ìŠ¤íŠ¸)ì™€ originalText(ì›ë³¸ í…ìŠ¤íŠ¸) ê°€ì ¸ì˜¤ê¸°
                        full_text = doc.get("fullText")  # ë²ˆì—­ëœ ì˜ì–´ í…ìŠ¤íŠ¸ (ëª¨ë¸ë§ìš©) - * ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„ë¨
                        original_text = doc.get("originalText")  # ì›ë³¸ í•œê¸€ í…ìŠ¤íŠ¸ (í‘œì‹œìš©) - * ê¸°ì¤€ìœ¼ë¡œ êµ¬ë¶„ë¨
                        structured_blocks = doc.get("structuredBlocks")
                        
                        if not full_text:
                            print(f"âš ï¸ [ë¬¸ì„œ {doc_id}] fullTextê°€ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                            processed_ids.add(doc_id)
                            continue
                        
                        # originalTextê°€ ì—†ìœ¼ë©´ fullTextë¥¼ ì›ë³¸ìœ¼ë¡œ ì‚¬ìš© (ê²½ê³ )
                        if not original_text:
                            original_text = full_text
                            print(f"âš ï¸ [ë¬¸ì„œ {doc_id}] originalTextê°€ ì—†ìŠµë‹ˆë‹¤. fullTextë¥¼ ì›ë³¸ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                        
                        # fullTextì— í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ëª¨ë¸ì— í•œê¸€ì´ ë“¤ì–´ê°€ë©´ ì•ˆ ë¨)
                        import re
                        has_korean_in_fulltext = bool(re.search(r'[ê°€-í£]', full_text))
                        if has_korean_in_fulltext:
                            print(f"âš ï¸ [ê²½ê³ ] fullTextì— í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤!")
                            print(f"   fullTextëŠ” ë°˜ë“œì‹œ ë²ˆì—­ëœ ì˜ì–´ í…ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤.")
                            print(f"   fullText ìƒ˜í”Œ: {full_text[:200]}")
                            sys.stdout.flush()
                        
                        # ìƒˆ ë¬¸ì„œ ê°ì§€ ë¡œê·¸
                        print("\n" + "=" * 80)
                        print(f"ğŸ“¥ [ìƒˆë¡œìš´ í¬ë¡¤ë§ ë°ì´í„° ê°ì§€]")
                        print("=" * 80)
                        print(f"ğŸ“ ë¬¸ì„œ ID: {doc_id}")
                        print(f"ğŸ“ URL: {doc.get('tabUrl', 'N/A')}")
                        print(f"ğŸ“„ ì œëª©: {doc.get('tabTitle', 'N/A')}")
                        print(f"ğŸ“Š í”„ë ˆì„ ìˆ˜: {doc.get('framesCollected', 0)}ê°œ")
                        print(f"ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(full_text)} ë¬¸ì")
                        sys.stdout.flush()
                        
                        # ë¸”ë¡ ê¸°ì¤€ ë¬¸ì¥ ìˆ˜ ê³„ì‚°
                        sentences = parse_text_blocks(full_text)
                        print(f"ğŸ“‹ ë¬¸ì¥ ìˆ˜ (# ê¸°ì¤€ ë¸”ë¡): {len(sentences)}ê°œ")
                        print(f"ğŸ“„ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {full_text[:150]}")
                        print("=" * 80)
                        sys.stdout.flush()
                        
                        try:
                            # structuredBlocks ê¸°ë°˜ ë¸”ë¡ êµ¬ì„± (íƒœê·¸/ì…€ë ‰í„° ìœ ì§€)
                            def star_to_plain(value: Optional[str]) -> str:
                                if not value:
                                    return ""
                                text_value = str(value).replace("*", " ")
                                return re.sub(r"\s+", " ", text_value).strip()
                            
                            block_entries: List[Dict[str, Any]] = []
                            if isinstance(structured_blocks, list) and structured_blocks:
                                for blk in structured_blocks:
                                    if not isinstance(blk, dict):
                                        continue
                                    translated_star = blk.get("text") or blk.get("plainText") or ""
                                    translated_plain = blk.get("translatedPlainText") or star_to_plain(translated_star)
                                    original_star = blk.get("originalText") or blk.get("rawText") or translated_star
                                    original_plain = blk.get("originalPlainText") or blk.get("rawPlainText") or star_to_plain(original_star)
                                    if not translated_plain and not original_plain:
                                        continue
                                    block_entries.append({
                                        "translated_star": translated_star,
                                        "translated_plain": translated_plain,
                                        "original_star": original_star,
                                        "original_plain": original_plain,
                                        "meta": {
                                            "index": blk.get("index"),
                                            "selector": blk.get("selector"),
                                            "tag": blk.get("tag"),
                                            "frameUrl": blk.get("frameUrl"),
                                            "frameTitle": blk.get("frameTitle"),
                                            "frameBlockIndex": blk.get("frameBlockIndex"),
                                            "blockType": blk.get("blockType"),
                                            "frameId": blk.get("frameId"),
                                            "linkHref": blk.get("linkHref"),
                                        }
                                    })
                            else:
                                translated_sentences = parse_text_blocks(full_text)
                                original_sentences = parse_text_blocks(original_text)
                                for idx, translated_plain in enumerate(translated_sentences):
                                    original_plain = original_sentences[idx] if idx < len(original_sentences) else translated_plain
                                    block_entries.append({
                                        "translated_star": translated_plain,
                                        "translated_plain": translated_plain,
                                        "original_star": original_plain,
                                        "original_plain": original_plain,
                                        "meta": {
                                            "index": idx,
                                            "linkHref": None
                                        }
                                    })
                            
                            # ì¤‘ë³µ ë¸”ë¡ ì œê±° (í…ìŠ¤íŠ¸ ê¸°ì¤€)
                            unique_entries = []
                            seen_entries = set()
                            for entry in block_entries:
                                text_key = (entry.get("original_plain") or entry.get("translated_plain") or "").strip().lower()
                                if not text_key:
                                    continue
                                if text_key in seen_entries:
                                    continue
                                seen_entries.add(text_key)
                                unique_entries.append(entry)
                            block_entries = unique_entries

                            total_count = len(block_entries)
                            if total_count == 0:
                                print(f"âš ï¸ [ê²½ê³ ] ì²˜ë¦¬í•  ë¸”ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ë¬¸ì„œ {doc_id} ê±´ë„ˆëœë‹ˆë‹¤.")
                                processed_ids.add(doc_id)
                                continue
                            
                            current_count = [0]
                            
                            def update_progress(current, total):
                                current_count[0] = current
                                try:
                                    extension_col.update_one(
                                        {"_id": doc_id},
                                        {"$set": {
                                            "modelingStatus": "processing",
                                            "modelingProgress.current": current,
                                            "modelingProgress.total": total_count,
                                            "processingServerId": SERVER_INSTANCE_ID
                                        }}
                                    )
                                except Exception as e:
                                    print(f"âš ï¸ [ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ ì‹¤íŒ¨] {str(e)}")
                            
                            extension_col.update_one(
                                {"_id": doc_id},
                                {"$set": {
                                    "modelingStatus": "processing",
                                    "modelingProgress": {"current": 0, "total": total_count},
                                    "processingServerId": SERVER_INSTANCE_ID
                                }}
                            )
                            
                            print(f"\nğŸ”„ [ëª¨ë¸ë§ ì‹œì‘] {total_count}ê°œ ë¸”ë¡ ì²˜ë¦¬ ì˜ˆì •\n")
                            sys.stdout.flush()
                            
                            print("ğŸš€ [ëª¨ë¸ ì‹¤í–‰ ì‹œì‘] process_text_and_predict() í˜¸ì¶œ")
                            sys.stdout.flush()
                            
                            translated_list_for_model = [entry["translated_plain"] for entry in block_entries]
                            results = process_text_and_predict(translated_list_for_model, progress_callback=update_progress)
                            
                            print(f"ğŸ“ [ì›ë³¸ í…ìŠ¤íŠ¸ ë§¤í•‘] ë¸”ë¡: {len(block_entries)}ê°œ, ê²°ê³¼: {len(results)}ê°œ")
                            sys.stdout.flush()
                            
                            for idx, result in enumerate(results):
                                if idx >= len(block_entries):
                                    break
                                entry = block_entries[idx]
                                result["original_text"] = entry["original_plain"]
                                result["structured_meta"] = entry["meta"]
                                result["translated_text"] = entry["translated_plain"]
                                if idx < 3:
                                    preview = entry["original_plain"] or entry["translated_plain"]
                                    print(f"   [{idx+1}] ì›ë³¸ ë§¤í•‘: {preview[:50]}")
                                    sys.stdout.flush()
                            
                            print(f"\nâœ… [ëª¨ë¸ë§ ì™„ë£Œ] ì´ {len(results)}ê°œ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œ\n")
                            sys.stdout.flush()
                            
                            if not results:
                                print(f"âš ï¸ [ê²½ê³ ] ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n")
                                processed_ids.add(doc_id)
                                continue
                            
                            dark_count = sum(1 for r in results if r.get("is_darkpattern") == 1)
                            normal_count = len(results) - dark_count
                            print("=" * 80)
                            print(f"ğŸ“Š [ëª¨ë¸ë§ ê²°ê³¼ í†µê³„]")
                            print(f"   - ì´ ì²˜ë¦¬: {len(results)}ê°œ")
                            print(f"   - ë‹¤í¬íŒ¨í„´: {dark_count}ê°œ")
                            print(f"   - ì¼ë°˜: {normal_count}ê°œ")
                            print(f"   - ë‹¤í¬íŒ¨í„´ ë¹„ìœ¨: {round(dark_count/len(results)*100, 1)}%")
                            print("=" * 80)
                            
                            print(f"\nğŸ’¾ [MongoDB ì €ì¥ ì‹œì‘] ê²°ê³¼ë¥¼ model ì»¬ë ‰ì…˜ì— ì €ì¥ ì¤‘\n")
                            saved_count = 0
                            dark_saved = 0
                            seen_result_docs = set()
                            
                            for idx, result in enumerate(results, 1):
                                try:
                                    prob_value = result.get("probability")
                                    probability_int = int(round(prob_value * 100)) if prob_value is not None else None
                                    is_dark = result.get("is_darkpattern", 0)
                                    
                                    entry = block_entries[idx - 1] if (idx - 1) < len(block_entries) else None
                                    original_string = result.get("original_text") or (entry.get("original_plain") if entry else "")
                                    translated_string = result.get("translated_text") or (entry.get("translated_plain") if entry else result.get("text", ""))
                                    
                                    if is_dark and idx <= 3:
                                        print(f"   ğŸ” [{idx}] ë‹¤í¬íŒ¨í„´ ì €ì¥ - ì›ë³¸: {original_string[:60]}")
                                        sys.stdout.flush()

                                    normalized_original = original_string.strip().lower()
                                    if normalized_original in seen_result_docs:
                                        continue
                                    seen_result_docs.add(normalized_original)
                                    
                                    meta_info = result.get("structured_meta") or (entry.get("meta") if entry else None)
                                    link_href_value = None
                                    link_selector_value = None
                                    if isinstance(meta_info, dict):
                                        link_href_value = meta_info.get("linkHref")
                                        link_selector_value = meta_info.get("linkSelector")

                                    result_doc = {
                                        "string": original_string,
                                        "translatedString": translated_string,
                                        "type": result.get("type"),
                                        "predicate": result.get("predicate"),
                                        "probability": probability_int,
                                        "is_darkpattern": is_dark,
                                        "id": str(doc_id),
                                        "structuredMeta": meta_info,
                                        "linkHref": link_href_value,
                                        "linkSelector": link_selector_value
                                    }
                                    model_col.insert_one(result_doc)
                                    saved_count += 1
                                    if is_dark:
                                        dark_saved += 1
                                    
                                    if idx % 10 == 0 or is_dark == 1:
                                        status = "ğŸ”´ ë‹¤í¬íŒ¨í„´" if is_dark else "âšª ì¼ë°˜"
                                        print(f"   [{idx}/{len(results)}] {status} ì €ì¥: {original_string[:60]}")
                                except Exception as save_error:
                                    print(f"âŒ [ì €ì¥ ì‹¤íŒ¨ {idx}/{len(results)}] {str(save_error)}")
                                    import traceback
                                    traceback.print_exc()
                            
                            extension_col.update_one(
                                {"_id": doc_id},
                                {"$set": {
                                    "modelingStatus": "completed",
                                    "modelingProgress": {"current": len(results), "total": total_count},
                                    "modelingCompletedAt": datetime.now(),
                                    "processingServerId": SERVER_INSTANCE_ID
                                }}
                            )
                            
                            processed_ids.add(doc_id)
                            print("\n" + "=" * 80)
                            print(f"âœ… [ì²˜ë¦¬ ì™„ë£Œ] ë¬¸ì„œ {doc_id}")
                            print(f"   - ì´ ì €ì¥: {saved_count}/{len(results)}ê°œ")
                            print(f"   - ë‹¤í¬íŒ¨í„´ ì €ì¥: {dark_saved}ê°œ")
                            print(f"   - Collection: model")
                            print(f"   - ì €ì¥ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                            print("=" * 80 + "\n")
                            sys.stdout.flush()
                            
                        except Exception as e:
                            # ëª¨ë¸ë§ ì‹¤íŒ¨ ìƒíƒœ ì—…ë°ì´íŠ¸
                            try:
                                extension_col.update_one(
                                    {"_id": doc_id},
                                    {"$set": {
                                        "modelingStatus": "failed",
                                        "modelingError": str(e),
                                        "processingServerId": SERVER_INSTANCE_ID
                                    }}
                                )
                            except:
                                pass
                            
                            print(f"\nâŒ [ì˜¤ë¥˜ ë°œìƒ] ë¬¸ì„œ {doc_id} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:")
                            print(f"   {str(e)}")
                            import traceback
                            traceback.print_exc()
                            print("=" * 80 + "\n")
                            sys.stdout.flush()
                            # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ processed_idsì— ì¶”ê°€í•˜ì—¬ ë¬´í•œ ë°˜ë³µ ë°©ì§€
                            processed_ids.add(doc_id)
                        
        except Exception as e:
            print(f"\nâŒ [Change Stream ì˜¤ë¥˜]")
            print(f"   ì˜¤ë¥˜: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # ì—°ê²° ì˜¤ë¥˜ì¸ ê²½ìš° ì¬ì‹œë„
            if "Connection" in str(e) or "ServerSelectionTimeoutError" in str(type(e).__name__):
                retry_count += 1
                if retry_count < max_retries:
                    print(f"   {5 * retry_count}ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤ ({retry_count}/{max_retries})\n")
                    time.sleep(5 * retry_count)
                    continue
                else:
                    print(f"\nâŒ [ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼] MongoDB ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                    print("ì„œë²„ë¥¼ ì¬ì‹œì‘í•˜ê±°ë‚˜ MongoDB ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.\n")
                    return
            else:
                # ë‹¤ë¥¸ ì˜¤ë¥˜ì¸ ê²½ìš° ì¬ì‹œë„
                print(f"   5ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤\n")
                time.sleep(5)
                continue

def start_watcher():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ MongoDB ê°ì‹œë¥¼ ì‹œì‘í•˜ëŠ” ìŠ¤ë ˆë“œ"""
    watcher_thread = threading.Thread(target=watch_extension_collection, daemon=True)
    watcher_thread.start()
    print("âœ… [ì‹œìŠ¤í…œ] MongoDB ê°ì‹œ ìŠ¤ë ˆë“œ ì‹œì‘ë¨")
    print("   - Extension ì»¬ë ‰ì…˜ ê°ì‹œ ì¤‘")
    print("   - ìƒˆ ë¬¸ì„œ ê°ì§€ ì‹œ ìë™ìœ¼ë¡œ ëª¨ë¸ë§ ìˆ˜í–‰\n")

if __name__ == "__main__":
    import socket
    
    PORT = int(os.getenv("PORT", 5005))  # í™˜ê²½ë³€ìˆ˜ë¡œ í¬íŠ¸ ì„¤ì • ê°€ëŠ¥
    
    # í¬íŠ¸ ì¶©ëŒ í™•ì¸ ë° ì²˜ë¦¬
    print("\n" + "=" * 80)
    print("ğŸ” [í¬íŠ¸ í™•ì¸] í¬íŠ¸ ì¶©ëŒ ì²´í¬ ì¤‘")
    print("=" * 80)
    
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    result = sock.connect_ex(('127.0.0.1', PORT))
    sock.close()
    
    if result == 0:
        print(f"\nâŒ [í¬íŠ¸ ì¶©ëŒ] í¬íŠ¸ {PORT}ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.")
        print("=" * 80)
        print("ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
        print(f"1. ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ: lsof -ti:{PORT} | xargs kill -9")
        print(f"2. í™˜ê²½ë³€ìˆ˜ë¡œ ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©: PORT=5006 python app.py")
        print("=" * 80 + "\n")
        import sys
        sys.exit(1)
    else:
        print(f"âœ… [í¬íŠ¸ í™•ì¸] í¬íŠ¸ {PORT} ì‚¬ìš© ê°€ëŠ¥")
        print("=" * 80 + "\n")
        
        # Flask ì„œë²„ ì‹œì‘ ì „ì— MongoDB ê°ì‹œ ì‹œì‘
        start_watcher()
        
        print("\n" + "=" * 80)
        print(f"ğŸš€ [Model ì„œë²„ ì‹œì‘]")
        print("=" * 80)
        print(f"ğŸ“ í¬íŠ¸: {PORT}")
        print(f"ğŸŒ URL: http://localhost:{PORT}")
        print("=" * 80 + "\n")
        
        app.run(host="0.0.0.0", port=PORT)