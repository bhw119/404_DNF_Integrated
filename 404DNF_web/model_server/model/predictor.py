import easyocr
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM
from sentence_transformers import SentenceTransformer
from torch_geometric.data import Data, Batch
import joblib
import json
import os
import sys
import pandas as pd
from model.resgcn import ResGCN_Improved

# stdout ë²„í¼ë§ ë¹„í™œì„±í™” (ë¡œê·¸ ì¦‰ì‹œ ì¶œë ¥)
sys.stdout.reconfigure(line_buffering=True)

# í˜„ìž¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_DIR = os.path.join(BASE_DIR)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# OCR ì—”ì§„ ì´ˆê¸°í™”
reader = easyocr.Reader(['en', 'ko'])

# 1ë‹¨ê³„ HuggingFace ëª¨ë¸ ë¡œë“œ (is_darkpattern ì—¬ë¶€ íŒë‹¨)
dp_tokenizer = AutoTokenizer.from_pretrained("h4shk4t/darkpatternLLM-multiclass")
dp_model = AutoModelForSequenceClassification.from_pretrained("h4shk4t/darkpatternLLM-multiclass")
dp_model.to(device)
dp_model.eval()

class_map = {
    0: "scarcity",
    1: "misdirection",
    2: "Not_Dark_Pattern",
    3: "obstruction",
    4: "forced_action",
    5: "sneaking",
    6: "social_proof",
    7: "urgency"
}

# ë²ˆì—­ ëª¨ë¸ ë¡œë“œ (ì˜->í•œ)
trans_model_name = "Helsinki-NLP/opus-mt-ko-en"
trans_tokenizer = AutoTokenizer.from_pretrained(trans_model_name)
trans_model = AutoModelForSeq2SeqLM.from_pretrained(trans_model_name).to(device)

# 2ë‹¨ê³„ ResGCN ëª¨ë¸ ë¡œë“œ (predicate ì˜ˆì¸¡)
# SentenceTransformer ë¡œë“œ (ìž„ë² ë”© ìƒì„±ìš©)
st_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2', device=device)
print(f"âœ… SentenceTransformer ë¡œë“œ ì™„ë£Œ (device: {device})")

# ResGCN ëª¨ë¸ ë¡œë“œ
model_path = os.path.join(MODEL_DIR, "resgcn_improved.pt")
predicate_encoder = joblib.load(os.path.join(MODEL_DIR, "label_encoders", "predicate_encoder.pkl"))
category_encoder = joblib.load(os.path.join(MODEL_DIR, "label_encoders", "category_encoder.pkl"))

print(f"ðŸ“¦ ResGCN ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì¤‘: {model_path}")
ckpt = torch.load(model_path, map_location=device)

# ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ
if 'hp' in ckpt:
    hp = ckpt['hp']
    in_dim = hp.get('in_dim', 768)  # all-mpnet-base-v2ì˜ ì°¨ì›
    hidden = hp.get('hidden', 128)
    num_blocks = hp.get('layers', 2)
else:
    # ê¸°ë³¸ê°’ ì‚¬ìš© (ckptì— hpê°€ ì—†ëŠ” ê²½ìš°)
    in_dim = 768
    hidden = 128
    num_blocks = 2
    print("âš ï¸  ì²´í¬í¬ì¸íŠ¸ì— hp ì •ë³´ê°€ ì—†ì–´ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# state_dict ì¶”ì¶œ
if 'state_dict' in ckpt:
    state_dict = ckpt['state_dict']
else:
    # ì „ì²´ ëª¨ë¸ì´ ì €ìž¥ëœ ê²½ìš°
    if isinstance(ckpt, dict) and 'model' in ckpt:
        state_dict = ckpt['model']
    else:
        # state_dictê°€ ì§ì ‘ ì €ìž¥ëœ ê²½ìš°
        state_dict = ckpt

# ì¶œë ¥ í´ëž˜ìŠ¤ ìˆ˜ëŠ” ì²´í¬í¬ì¸íŠ¸ì—ì„œ í™•ì¸í•˜ê±°ë‚˜ predicate_encoderì—ì„œ ê°€ì ¸ì˜´
if 'head.weight' in state_dict:
    num_classes = state_dict['head.weight'].shape[0]
    print(f"ðŸ“Š ì²´í¬í¬ì¸íŠ¸ì—ì„œ num_classes í™•ì¸: {num_classes}")
else:
    num_classes = len(predicate_encoder.classes_)
    print(f"âš ï¸  ì²´í¬í¬ì¸íŠ¸ì— head.weightê°€ ì—†ì–´ predicate_encoderì—ì„œ ê°€ì ¸ì˜´: {num_classes}")

print(f"ðŸ“Š ëª¨ë¸ ì„¤ì •: in_dim={in_dim}, hidden={hidden}, num_classes={num_classes}, num_blocks={num_blocks}")

# ResGCN ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
model = ResGCN_Improved(in_dim=in_dim, hidden=hidden, num_classes=num_classes, num_blocks=num_blocks)

# state_dict ë¡œë“œ
model.load_state_dict(state_dict)
print("âœ… ëª¨ë¸ state_dict ë¡œë“œ ì™„ë£Œ")

model.to(device)
model.eval()
print(f"âœ… ResGCN ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (device: {device})")

# ì˜ˆì¸¡ í•¨ìˆ˜ (ë‘ ë‹¨ê³„ ë¶„ê¸° + ë²ˆì—­ í¬í•¨)
def process_image_and_predict(image_path):
    law_path = os.path.join(MODEL_DIR, "predicate_type_law.csv")
    if os.path.exists(law_path):
        laws_df = pd.read_csv(law_path)
        # predicate, type, laws ëª¨ë‘ í¬í•¨í•´ì•¼ í•¨ (predicateë¡œ ê²€ìƒ‰í•˜ê¸° ìœ„í•´)
        reduced_law = laws_df[['predicate', 'type', 'laws']].drop_duplicates().reset_index(drop=True)
    else:
        reduced_law = pd.DataFrame(columns=['predicate', 'type', 'laws'])

    ocr_results = reader.readtext(image_path)
    output = []

    for (bbox, text, prob) in ocr_results:
        x_min = int(min(p[0] for p in bbox))
        y_min = int(min(p[1] for p in bbox))
        width = int(max(p[0] for p in bbox)) - x_min
        height = int(max(p[1] for p in bbox)) - y_min

        # ë²ˆì—­: ì˜ì–´ â†’ í•œêµ­ì–´
        input_text = text.strip()
        try:
            trans_inputs = trans_tokenizer.encode(input_text, return_tensors="pt", truncation=True).to(device)
            translated = trans_model.generate(trans_inputs, max_length=100)
            translated_text = trans_tokenizer.decode(translated[0], skip_special_tokens=True)
        except Exception:
            translated_text = input_text  # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë¬¸ ìœ ì§€

        # âœ… ì˜ˆì¸¡ ê¸°ì¤€ì„ ë²ˆì—­ëœ í…ìŠ¤íŠ¸ë¡œ ë³€ê²½
        # 1ë‹¨ê³„: ë‹¤í¬íŒ¨í„´ ì—¬ë¶€ íŒë‹¨
        dp_inputs = dp_tokenizer(translated_text, return_tensors="pt", truncation=True, padding=True).to(device)
        with torch.no_grad():
            logits = dp_model(**dp_inputs).logits
            probs = F.softmax(logits, dim=1)[0]
            pred_class = torch.argmax(probs).item()
            pred_label = class_map[pred_class]

        is_dark = 0 if pred_label == "Not_Dark_Pattern" else 1
        category, predicate, top_preds = None, None, []

        # 2ë‹¨ê³„: ë‹¤í¬íŒ¨í„´ì¼ ê²½ìš° predicate ì˜ˆì¸¡ (ResGCN ì‚¬ìš©)
        if is_dark:
            try:
                # SentenceTransformerë¡œ ìž„ë² ë”© ìƒì„±
                with torch.no_grad():
                    embedding = st_model.encode([translated_text], convert_to_tensor=True, device=device)  # [1, 768]
                
                # 1-ë…¸ë“œ PyG Data ê°ì²´ ìƒì„±
                x = embedding  # [1, 768]
                edge_index = torch.empty((2, 0), dtype=torch.long, device=device)  # ë¹ˆ ì—£ì§€
                pyg_data = Data(x=x, edge_index=edge_index)
                
                # Batchë¡œ ë³€í™˜
                pyg_batch = Batch.from_data_list([pyg_data])
                pyg_batch = pyg_batch.to(device)
                
                # ResGCN ëª¨ë¸ ì¶”ë¡ 
                with torch.no_grad():
                    logits = model(pyg_batch)  # [1, num_classes]
                
                # ê²°ê³¼ í›„ì²˜ë¦¬
                pred_probs = F.softmax(logits, dim=-1).cpu().numpy()[0]
                pred_idx = torch.argmax(logits, dim=1).item()
                
                # Predicate ë””ì½”ë”©
                predicate = predicate_encoder.inverse_transform([pred_idx])[0]
                
                # Top 3 predictions
                top_indices = pred_probs.argsort()[::-1][:3]
                top_preds = [
                    f"{predicate_encoder.inverse_transform([i])[0]} ({round(pred_probs[i], 4)})"
                    for i in top_indices
                ]
                
                # CategoryëŠ” predicate_type_law.csvì—ì„œ predicateë¡œë¶€í„° ë§¤í•‘
                category = None
                if predicate:
                    category_row = reduced_law[reduced_law["predicate"] == predicate]
                    if not category_row.empty:
                        category = category_row.iloc[0]["type"]
            except Exception as e:
                print(f"[WARNING] ResGCN ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                predicate = None
                top_preds = []
                category = None

        # ë²•ë¥  ì •ë³´ ì—°ê²°
        law_list = []
        if category:
            law_row = reduced_law[reduced_law["type"] == category]
            if not law_row.empty:
                try:
                    law_list = json.loads(law_row.iloc[0]["laws"])
                except Exception as e:
                    print(f"[WARNING] JSON parsing error in laws: {e}")

        output.append({
            "text": text,
            "translated": translated_text,
            "confidence": float(prob),
            "bbox": json.dumps({"x": x_min, "y": y_min, "width": width, "height": height}),
            "is_darkpattern": is_dark,
            "predicate": predicate,
            "top1_predicate": top_preds[0] if len(top_preds) > 0 else None,
            "top2_predicate": top_preds[1] if len(top_preds) > 1 else None,
            "top3_predicate": top_preds[2] if len(top_preds) > 2 else None,
            "category": category,
            "type": category,
            "laws": law_list
        })

    return output

# í…ìŠ¤íŠ¸ ê¸°ë°˜ ì˜ˆì¸¡ í•¨ìˆ˜ (* ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬)
def process_text_and_predict(full_text, progress_callback=None):
    """
    fullTextë¥¼ * ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ê° í…ìŠ¤íŠ¸ì— ëŒ€í•´ ëª¨ë¸ ì˜ˆì¸¡ ìˆ˜í–‰
    
    Args:
        full_text: *ë¡œ êµ¬ë¶„ëœ í…ìŠ¤íŠ¸ ë¬¸ìžì—´
        
    Returns:
        ê° í…ìŠ¤íŠ¸ë³„ ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
    """
    law_path = os.path.join(MODEL_DIR, "predicate_type_law.csv")
    if os.path.exists(law_path):
        laws_df = pd.read_csv(law_path)
        # predicate, type, laws ëª¨ë‘ í¬í•¨í•´ì•¼ í•¨ (predicateë¡œ ê²€ìƒ‰í•˜ê¸° ìœ„í•´)
        reduced_law = laws_df[['predicate', 'type', 'laws']].drop_duplicates().reset_index(drop=True)
    else:
        reduced_law = pd.DataFrame(columns=['predicate', 'type', 'laws'])
    
    # * ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„ë¦¬ (fullTextëŠ” ì´ë¯¸ ë²ˆì—­ëœ ì˜ì–´ í…ìŠ¤íŠ¸)
    text_list = [text.strip() for text in full_text.split("*") if text.strip()]
    print(f"ðŸ“Š [í…ìŠ¤íŠ¸ ë¶„ë¦¬] * ê¸°ì¤€ìœ¼ë¡œ {len(text_list)}ê°œ í…ìŠ¤íŠ¸ ë°œê²¬ (ë²ˆì—­ëœ ì˜ì–´ í…ìŠ¤íŠ¸)")
    output = []
    
    for idx, text in enumerate(text_list, 1):
        input_text = text.strip()
        if not input_text:
            continue
        
        # ì§„í–‰ ìƒí™© ì½œë°± í˜¸ì¶œ (ìžˆëŠ” ê²½ìš°)
        if progress_callback:
            try:
                progress_callback(idx, len(text_list))
            except Exception as e:
                print(f"âš ï¸ [ì§„í–‰ ìƒí™© ì½œë°± ì˜¤ë¥˜] {str(e)}")
        
        # ì§„í–‰ ìƒí™© ë¡œê·¸ (ëª¨ë“  ë‹¨ê³„ì—ì„œ ì¶œë ¥)
        print(f"  ðŸ”„ [{idx}/{len(text_list)}] ëª¨ë¸ë§ ì§„í–‰ ì¤‘ ({input_text[:50]})")
        sys.stdout.flush()  # ë²„í¼ ê°•ì œ ì¶œë ¥
        
        # fullTextëŠ” ì´ë¯¸ í¬ë¡¬ ìµìŠ¤í…ì…˜ì—ì„œ ë²ˆì—­ëœ ì˜ì–´ í…ìŠ¤íŠ¸
        # ëª¨ë¸ì— ë“¤ì–´ê°€ëŠ” í…ìŠ¤íŠ¸ëŠ” ë°˜ë“œì‹œ ì˜ì–´ì—¬ì•¼ í•¨
        translated_text = input_text  # ì´ë¯¸ ë²ˆì—­ëœ í…ìŠ¤íŠ¸
        
        # í•œê¸€ ê°ì§€ ë° ê²½ê³  (ëª¨ë¸ì— í•œê¸€ì´ ë“¤ì–´ê°€ë©´ ì•ˆ ë¨)
        import re
        has_korean = bool(re.search(r'[ê°€-íž£]', translated_text))
        if has_korean:
            print(f"     âš ï¸ [ê²½ê³ ] ëª¨ë¸ì— í•œê¸€ í…ìŠ¤íŠ¸ê°€ ìž…ë ¥ë˜ì—ˆìŠµë‹ˆë‹¤! (ë²ˆì—­ í™•ì¸ í•„ìš”)")
            print(f"     ìž…ë ¥ í…ìŠ¤íŠ¸: {translated_text[:100]}")
            sys.stdout.flush()
        
        category, predicate, probability, top_preds = None, None, None, []
        is_dark = 0
        
        # ResGCN ëª¨ë¸ë¡œ ì§ì ‘ ì˜ˆì¸¡ (1-2ë‹¨ê³„ êµ¬ë¶„ ì—†ì´)
        print(f"     ðŸ“Š ResGCN ëª¨ë¸ ì˜ˆì¸¡ ì¤‘ (ìž…ë ¥: {len(translated_text)}ìž)")
        sys.stdout.flush()
        
        try:
            # SentenceTransformerë¡œ ìž„ë² ë”© ìƒì„±
            with torch.no_grad():
                embedding = st_model.encode([translated_text], convert_to_tensor=True, device=device)  # [1, 768]
            
            # 1-ë…¸ë“œ PyG Data ê°ì²´ ìƒì„±
            x = embedding  # [1, 768]
            edge_index = torch.empty((2, 0), dtype=torch.long, device=device)  # ë¹ˆ ì—£ì§€ (1-ë…¸ë“œ ê·¸ëž˜í”„)
            pyg_data = Data(x=x, edge_index=edge_index)
            
            # Batchë¡œ ë³€í™˜ (ë‹¨ì¼ ê·¸ëž˜í”„ì´ë¯€ë¡œ ë°°ì¹˜ í¬ê¸° 1)
            pyg_batch = Batch.from_data_list([pyg_data])
            pyg_batch = pyg_batch.to(device)
            
            # ResGCN ëª¨ë¸ ì¶”ë¡ 
            with torch.no_grad():
                logits = model(pyg_batch)  # [1, num_classes]
            
            # ê²°ê³¼ í›„ì²˜ë¦¬
            pred_probs = F.softmax(logits, dim=-1).cpu().numpy()[0]  # [num_classes]
            pred_idx = torch.argmax(logits, dim=1).item()
            
            # Predicate ë””ì½”ë”©
            predicate = predicate_encoder.inverse_transform([pred_idx])[0]
            probability = float(pred_probs[pred_idx])
            
            # ë‹¤í¬íŒ¨í„´ ì—¬ë¶€ íŒë‹¨: predicateê°€ "Not_Dark_Pattern"ì´ ì•„ë‹ˆë©´ ë‹¤í¬íŒ¨í„´
            # ë˜ëŠ” í™•ë¥ ì´ ì¼ì • ìž„ê³„ê°’ ì´ìƒì´ë©´ ë‹¤í¬íŒ¨í„´ìœ¼ë¡œ íŒë‹¨
            is_not_dark_keywords = ["not_dark", "not_dark_pattern", "normal", "none"]
            is_dark = 1 if not any(keyword in predicate.lower() for keyword in is_not_dark_keywords) else 0
            
            # Top 3 predictions
            top_indices = pred_probs.argsort()[::-1][:3]
            top_preds = [
                f"{predicate_encoder.inverse_transform([i])[0]} ({round(pred_probs[i], 4)})"
                for i in top_indices
            ]
            
            # CategoryëŠ” predicate_type_law.csvì—ì„œ predicateë¡œë¶€í„° ë§¤í•‘
            if predicate:
                category_row = reduced_law[reduced_law["predicate"] == predicate]
                if not category_row.empty:
                    category = category_row.iloc[0]["type"]
            
            # ê²°ê³¼ ë¡œê·¸
            if is_dark:
                print(f"     ðŸ”´ ë‹¤í¬íŒ¨í„´ ê°ì§€: Type={category}, Predicate={predicate}, í™•ë¥ ={round(probability*100, 1)}%")
            else:
                print(f"     âšª ì¼ë°˜ í…ìŠ¤íŠ¸: Predicate={predicate}, í™•ë¥ ={round(probability*100, 1)}%")
            sys.stdout.flush()
            
        except Exception as e:
            print(f"     âŒ ResGCN ì˜ˆì¸¡ ì‹¤íŒ¨: {str(e)}")
            import traceback
            traceback.print_exc()
            sys.stdout.flush()
            predicate = None
            probability = None
            top_preds = []
            category = None
            is_dark = 0
        
        # ë²•ë¥  ì •ë³´ ì—°ê²°
        law_list = []
        if category:
            law_row = reduced_law[reduced_law["type"] == category]
            if not law_row.empty:
                try:
                    law_list = json.loads(law_row.iloc[0]["laws"])
                except Exception as e:
                    print(f"[WARNING] JSON parsing error in laws: {e}")
        
        output.append({
            "text": translated_text,  # ë²ˆì—­ëœ í…ìŠ¤íŠ¸ (ëª¨ë¸ë§ì— ì‚¬ìš©ëœ í…ìŠ¤íŠ¸)
            "translated": translated_text,  # í˜¸í™˜ì„± ìœ ì§€
            "is_darkpattern": is_dark,
            "predicate": predicate,
            "probability": probability,
            "top1_predicate": top_preds[0] if len(top_preds) > 0 else None,
            "top2_predicate": top_preds[1] if len(top_preds) > 1 else None,
            "top3_predicate": top_preds[2] if len(top_preds) > 2 else None,
            "category": category,
            "type": category,
            "laws": law_list
        })
    
    return output